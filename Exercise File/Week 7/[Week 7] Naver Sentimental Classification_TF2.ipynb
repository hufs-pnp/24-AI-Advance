{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"553px","left":"792px","right":"61px","top":"71px","width":"375px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"9oq4UnWajC9u"},"source":["# Sentiment Classification\n","\n","### Task\n","* 네이버에서 영화평을 가지고 positive/negative인지 구분해보자.\n","* 데이터 불러오기를 제외한 딥러닝 트레이닝 과정을 직접 구현해보는 것이 목표 입니다.\n","\n","### Dataset\n","* [Naver sentiment movie corpus v1.0](https://github.com/e9t/nsmc/)\n","\n","### Base code\n","* Dataset: train, val, test로 split\n","* Input data shape: (`batch_size`, `max_sequence_length`)\n","* Output data shape: (`batch_size`, 1)\n","* Training\n","* Evaluation\n","\n","### Try some techniques\n","* Training-epochs 조절\n","* Change model architectures (Custom model)\n","  * Use another cells (LSTM, GRU, etc.)\n","  * Use dropout layers\n","* Embedding size 조절\n","  * 또는 one-hot vector로 학습\n","* Number of words in the vocabulary 변화\n","* `pad` 옵션 변화\n","* Data augmentation (if possible)"]},{"cell_type":"markdown","metadata":{"id":"OW9rRFr4jC9w"},"source":["## Import modules"]},{"cell_type":"code","metadata":{"id":"ibO_zjJmvN3s"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"id":"CgCS8iATktuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ct7ZVZ2EjC9x"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import unicode_literals\n","\n","import os\n","import time\n","import shutil\n","import tarfile\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from IPython.display import clear_output\n","import urllib.request\n","\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import sentencepiece as spm\n","\n","from collections import Counter, defaultdict\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-e3ucn5_jC90"},"source":["## Load Data\n","\n","* ratings_train.txt: 훈련용으로 사용되는 15만 개의 리뷰\n","* ratings_test.txt: 테스트용으로 보류된 5만 개의 리뷰\n","* 모든 리뷰는 140자 이내입니다\n","* 각 감정 클래스는 동등하게 샘플링되었습니다 (즉, 무작위 추측은 50%의 정확도를 보입니다)\n","* 10만 개의 부정적 리뷰 (원래 1-4점의 리뷰)\n","* 10만 개의 긍정적 리뷰 (원래 9-10점의 리뷰)\n","* 중립적 리뷰 (원래 5-8점의 리뷰)는 제외되었습니다\n"]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"metadata":{"id":"FBqk_wq-RIYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = pd.read_table('ratings_train.txt')\n","train_data = train_data.dropna()\n","test_data = pd.read_table('ratings_test.txt')\n","test_data = test_data.dropna()"],"metadata":{"id":"pB4ds-e1RavF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.head()"],"metadata":{"id":"xdMHf_rOSGXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data.head()"],"metadata":{"id":"rGCz3J5N3JeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tokenizing\n"],"metadata":{"id":"Eq0jwEhcSThR"}},{"cell_type":"code","source":["sp = spm.SentencePieceProcessor()\n","sp.load('/content/drive/MyDrive/dataset/naver_review/naver_review.model')  # 모델 경로 설정\n","\n","# 토크나이저 함수 정의\n","def tokenizer(text):\n","    return sp.encode_as_pieces(#TODO)"],"metadata":{"id":"WEfUnWZyT8px"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, (line) in enumerate(#TODO):\n","    print(#TODO)\n","    print(sp.encode_as_pieces(#TODO))\n","    print(sp.encode_as_ids(#TODO))\n","    if i == 5:\n","        break"],"metadata":{"id":"xPWz7QU_UFBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eos_token = '[SEP]'\n","eos_id = sp.piece_to_id(eos_token)\n","\n","print(f\"토큰 '{eos_token}'의 ID: {eos_id}\")"],"metadata":{"id":"cHyID7qIRoWz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sp.encode_as_ids(['[EOS]'])"],"metadata":{"id":"fAB1othYFZi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_text = []\n","for i, line in enumerate(#TODO):\n","    # sp.encode_as_ids(line)의 결과를 TensorFlow 텐서로 변환\n","    train_text.append(tf.convert_to_tensor(sp.encode_as_ids(line), dtype=tf.int32))\n","\n","test_text = []\n","for i, line in enumerate(#TODO):\n","    test_text.append(tf.convert_to_tensor(sp.encode_as_ids(line), dtype=tf.int32))"],"metadata":{"id":"KFV87kQjeEDC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_text), len(test_text))"],"metadata":{"id":"I4OeUYsx9OQ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z8yYy2OPjC-a"},"source":["### Padding and truncating data using pad sequences\n","* 전부 길이가 다른 리뷰들의 길이를 통일해주자"]},{"cell_type":"code","source":["batch_size = 32\n","max_seq_length = 256"],"metadata":{"id":"SPV-UWrwQMvX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_pad = pad_sequences(#TODO)\n","test_data_pad = pad_sequences(#TODO)\n","\n","print(train_data_pad.shape, test_data_pad.shape)"],"metadata":{"id":"_QB_qLXV3u_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9CPqHeI9y7g2"},"source":["### Dataset 구성"]},{"cell_type":"code","source":["batch_size = 32\n","\n","# for train\n","train_dataset = tf.data.Dataset.from_tensor_slices((#TODO))\n","train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size)\n","print(train_dataset)\n","\n","# for test\n","test_dataset = tf.data.Dataset.from_tensor_slices((#TODO))\n","test_dataset = test_dataset.batch(batch_size=batch_size)\n","print(test_dataset)"],"metadata":{"id":"pi43bh7G7NwG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SMG2MOXUjC-y"},"source":["## Build the model\n"]},{"cell_type":"markdown","metadata":{"id":"I5KBM5sdjC-v"},"source":["## Setup hyper-parameters"]},{"cell_type":"code","source":["kargs = {'model_name': 'BERT',\n","         'num_layers': #TODO,\n","         'd_model': #TODO,\n","         'num_heads': #TODO,\n","         'dff': #TODO,\n","         'input_vocab_size': sp.get_piece_size(),\n","         'target_vocab_size': sp.get_piece_size(),\n","         'maximum_position_encoding': #TODO,\n","         'segment_encoding': 2,\n","         'end_token_idx': sp.piece_to_id('[EOS]'),\n","         'rate': 0.1\n","        }"],"metadata":{"id":"cnhhKDlP8CqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model))\n","    return pos * angle_rates"],"metadata":{"id":"LvflfLNJsmYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","\n","    # apply sin to even indices in the array; 2i\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # apply cos to odd indices in the array; 2i+1\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"],"metadata":{"id":"VMSqmsT9ssT9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\"Calculate the attention weights.\n","    q, k, v must have matching leading dimensions.\n","    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","    The mask has different shapes depending on its type(padding or look ahead)\n","    but it must be broadcastable for addition.\n","\n","    Args:\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: Float tensor with shape broadcastable\n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","\n","    Returns:\n","    output, attention_weights\n","    \"\"\"\n","\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights"],"metadata":{"id":"e5fQof6usttB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = kargs['num_heads']\n","        self.d_model = kargs['d_model']\n","\n","        assert self.d_model % self.num_heads == 0\n","\n","        self.depth = self.d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n","        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n","        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n","\n","        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention,\n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","\n","        return output, attention_weights"],"metadata":{"id":"xWju3MTjsub-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def point_wise_feed_forward_network(**kargs):\n","    return tf.keras.Sequential([\n","            tf.keras.layers.Conv1D(#TODO),  # (batch_size, seq_len, dff)\n","            tf.keras.layers.Conv1D(#TODO)  # (batch_size, seq_len, d_model)\n","        ])\n"],"metadata":{"id":"10a_ZGMasyvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(**kargs)\n","\n","        self.ffn = point_wise_feed_forward_network(**kargs)\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n","        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n","\n","    @tf.function\n","    def call(self, x, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output)\n","        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output)\n","        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        return out2, attn_output"],"metadata":{"id":"MAeS5HH8Sb0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = kargs['d_model']\n","        self.num_layers = kargs['num_layers']\n","\n","        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'],\n","                                                   self.d_model)\n","        self.seg_encoding = tf.keras.layers.Embedding(kargs['segment_encoding'],\n","                                                   self.d_model)\n","        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'],\n","                                                     self.d_model)\n","\n","        self.enc_layers = [EncoderLayer(**kargs)\n","                           for _ in range(self.num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n","\n","    def get_seg_data(self, data, token_id=4):\n","        token_found = tf.cumsum(tf.cast(data == token_id, tf.int32), axis=1)\n","        modified_data = tf.cast(token_found >= 1, tf.int32)\n","\n","        return modified_data\n","\n","    def call(self, x, mask):\n","        attn = None\n","        seq_len = tf.shape(x)[1]\n","        seg_data = self.get_seg_data(x)\n","\n","        # adding embedding and position encoding.\n","        x = self.embedding(#TODO)  # (batch_size, input_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x += self.seg_encoding(#TODO)\n","\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x, attn = self.enc_layers[i](x, mask)\n","\n","        return x, attn  # (batch_size, input_seq_len, d_model)\n"],"metadata":{"id":"Hh-S4n1tTMro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERT(tf.keras.Model):\n","    def __init__(self, **kargs):\n","        super(BERT, self).__init__(name=kargs['model_name'])\n","        self.end_token_idx = kargs['end_token_idx']\n","        self.encoder = Encoder(**kargs)\n","        self.outputs_layer = tf.keras.layers.Dense(kargs['d_model'],\n","                                                   activation='tanh')\n","\n","        self.final_layer = tf.keras.layers.Dense(#TODO)\n","\n","    def create_padding_mask(self, seq):\n","        seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","\n","        # add extra dimensions to add the padding\n","        # to the attention logits.\n","        return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n","\n","    def call(self, x):\n","        inp = x\n","        mask = self.create_padding_mask(inp)\n","\n","        enc_output, attn = self.encoder(inp, mask)  # (batch_size, inp_seq_len, d_model)\n","        enc_output = self.outputs_layer(enc_output)  # (batch_size, inp_seq_len, d_model)\n","        enc_output = tf.keras.layers.Flatten()(#TODO)  # (batch_size, inp_seq_len * d_model)\n","        final_output = self.final_layer(#TODO)  # (batch_size, 1)\n","\n","        return final_output\n"],"metadata":{"id":"5ECeQU2bV_nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BERT(**kargs)"],"metadata":{"id":"QX6TMRTnWfjt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cruLtRx2jC_C"},"source":["## Train the model"]},{"cell_type":"code","source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=#TODO, reduction='none')\n","\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","\n","def loss(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)\n","\n","def accuracy(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n","    pred *= mask\n","    acc = train_accuracy(real, pred)\n","\n","    return tf.reduce_mean(acc)"],"metadata":{"id":"qswjggp_i0r1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=tf.keras.optimizers.Adam(#TODO),\n","              loss=loss,\n","              metrics=[accuracy])"],"metadata":{"id":"IHJgMz0AitbW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n","                                                     monitor='val_loss',\n","                                                     restore_best_weights=True,\n","                                                     verbose=1)"],"metadata":{"id":"fE8AQSGyW0b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(#TODO)\n"],"metadata":{"id":"qMhtscA7WoiK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test the model"],"metadata":{"id":"YWB5yVQonm1m"}},{"cell_type":"code","source":["results = model.evaluate(test_dataset)\n","# loss\n","print(\"loss value: {:.3f}\".format(results[0]))\n","# accuracy\n","print(\"accuracy value: {:.3f}\".format(results[1]))"],"metadata":{"id":"-c8qXnK1nobL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-40F3YgugDwS"},"execution_count":null,"outputs":[]}]}